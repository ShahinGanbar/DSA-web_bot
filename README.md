Web-bot: Interactive Data Analysis Assistant ğŸ¤–

A Streamlit-based web application that provides an intelligent data analysis assistant powered by Google's Gemini AI. Upload your CSV datasets and get instant insights through natural language queries, automated code generation, and interactive visualizationsâ€”all running inside Docker.

âœ¨ Features

ğŸ“Š Smart Data Analysis: Ask questions about your data in natural language

ğŸ¤– AI-Powered Code Generation: Automatically generates Python code for data manipulation, statistics, and visualizations

ğŸ“ˆ Auto-Rendering Plots: Supports Plotly and Matplotlib/Seaborn

ğŸ”’ Safe Code Execution: Runs generated code in a controlled environment

ğŸ’¾ Session Management: Maintains analysis history and data state

ğŸ“‹ Interactive UI: Clean, modern interface with expandable chat history

ğŸš€ Quick Start (Docker)
Prerequisites

Docker & Docker Compose installed

Google Gemini API key

1ï¸âƒ£ Clone the repository
git clone <your-repo-url>
cd Web-bot

2ï¸âƒ£ Set up environment variables

Create a .env file in the project root:

GOOGLE_API_KEY=your_gemini_api_key_here
OPENAI_API_KEY=your_openai_api_key_here  # if using OpenAI models

3ï¸âƒ£ Build and run with Docker Compose
docker compose up --build


The first build may take a few minutes.

Your app will be available at: http://localhost:8501

âœ… Streamlit, dependencies, and API keys are all configured inside the container.

4ï¸âƒ£ Stopping the app
docker compose down


This stops the container and frees port 8501.

ğŸ“ Project Structure
Web-bot/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ streamlit_app.py      # Main Streamlit application
â”‚   â”œâ”€â”€ llm/
â”‚   â”‚   â””â”€â”€ chain.py          # LLM chain management and prompts
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ data_utils.py     # Data utilities and code execution
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ .env                      # Environment variables (create this)
â”œâ”€â”€ Dockerfile                # Docker image definition
â”œâ”€â”€ docker-compose.yml        # Docker Compose configuration
â””â”€â”€ README.md                 # This file

ğŸ”§ How It Works

Data Upload: Upload CSVs; pandas loads data and extracts schema.

Natural Language Queries: Ask questions; LLM decides whether to explain or generate code.

Code Generation & Execution: Python code runs safely; plots auto-render.

Session Management: Keeps your data state and history.

ğŸ’¡ Usage Examples

"What's the average value of numeric columns?"

"Create a correlation matrix heatmap"

"Filter rows where column X > 100"

"Show me a pairplot of the features"

ğŸ›¡ï¸ Safety Features

No direct file I/O

Controlled environment with limited system access

Auto-package management for missing dependencies

Graceful error handling

ğŸ”Œ Configuration
Environment Variables

GOOGLE_API_KEY â€” Required for Gemini AI

OPENAI_API_KEY â€” Required if using OpenAI models

Docker Ports

8501:8501 (host:container) by default

ğŸš§ Limitations

Currently supports CSV files only

Requires internet connection for LLM API calls

Large datasets may impact performance

ğŸ¤ Contributing

Fork the repository

Create a feature branch (git checkout -b feature/amazing-feature)

Commit changes (git commit -m 'Add amazing feature')

Push (git push origin feature/amazing-feature)

Open a Pull Request

ğŸ“ License

MIT License â€” see the LICENSE file for details.

ğŸ™ Acknowledgments

Streamlit

Google Gemini

LangChain

Pandas

Plotly and Matplotlib